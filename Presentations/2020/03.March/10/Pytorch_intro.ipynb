{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch is a Python library used to implement ML models. It was developer by Facebook researchers. It allows to execute code on CUDA devices or ordinary CPUs; [some support for AMD devices also exist](https://rocm.github.io/pytorch.html), and [there are some effors to run PyTorch on Google's TPUs](https://github.com/pytorch/xla). It is prefered by many developers to implement deep learning models. Unlike other high level libraries (like Keras), it allows forfull customization of learning models. Custom optimization algorithms, less functions etc can be easily added by a programmer, besides the existing ones. \n",
    "\n",
    "It favours developing NNs as dynamical computation graphs, i.e. the structure of the neural network can be decide at runtime. A major plus is auto-differentiation module, which allows one to automatically computer the gradients and use them to modify the weights. Thus, gradient based optimiziation models are easily to be implemented.\n",
    "\n",
    "The official documentation can be found at [Pytorch documentation site](https://pytorch.org/docs/stable/index.html). There are plenty of free resources, like [Pytorch forums](https://discuss.pytorch.org) or [book DEEP LEARNING WITH PYTORCH](https://pytorch.org/deep-learning-with-pytorch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The official installation details are at [https://pytorch.org](https://pytorch.org); we recommend you to follow the steps from this page, as the packages (e.g. cudatookit) are continuously released under different version numbers. It is recommended to create a Python virtual environment, e.g. via `conda`:\n",
    "```\n",
    "conda create --name pytorch anaconda --yes\n",
    "```\n",
    "followed by `conda activate pytorch && conda update --all --yes`. \n",
    "\n",
    "If an NVIDIA GPU is avialable, Pytorch can be installed as:\n",
    "```\n",
    "conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n",
    "```\n",
    "If only CPU is to be used, one can install a GPUless distribution as:\n",
    "```\n",
    "conda install pytorch torchvision cpuonly -c pytorch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic notions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a `Tensor` object is a multidimensional array similar to NumPy arrays\n",
    "* class `Dataset`: bridge between your data and n dimensional `Tensor` objects\n",
    "* class `DataLoader`: loads data from a `Dataset` objects and launches child processes to prepare data for training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allows one to represent data and trainable weights. \n",
    "![Tensor drawings](./images/tensors.png)\n",
    "Image source: Ref. 2. \n",
    "\n",
    "Unlike NumPy arrays, PyTorch tensors can be loaded into GPUs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:17.161420Z",
     "start_time": "2020-03-09T21:13:16.531263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:17.172360Z",
     "start_time": "2020-03-09T21:13:17.163384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:17.185325Z",
     "start_time": "2020-03-09T21:13:17.176347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16.,  1., 25.,  9.,  4.,  1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:17.196295Z",
     "start_time": "2020-03-09T21:13:17.187319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points2 = points.reshape(3, 2)\n",
    "points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:17.203287Z",
     "start_time": "2020-03-09T21:13:17.198289Z"
    }
   },
   "outputs": [],
   "source": [
    "# points and points2 share the same memory\n",
    "points2[1, 1] *= -1\n",
    "points\n",
    "assert id(points.storage()) == id(points2.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:17.215247Z",
     "start_time": "2020-03-09T21:13:17.207266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  5.,  2.],\n",
       "        [ 1., -3.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:17.234229Z",
     "start_time": "2020-03-09T21:13:17.220232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_d_array = torch.ones(3, 4, 7)\n",
    "three_d_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:17.245166Z",
     "start_time": "2020-03-09T21:13:17.236190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "double_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:17.255137Z",
     "start_time": "2020-03-09T21:13:17.247158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert from numpy to torch and the other way around\n",
    "points = torch.ones(3, 4)\n",
    "points_np = points.numpy()\n",
    "type(points_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:17.269101Z",
     "start_time": "2020-03-09T21:13:17.259127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.from_numpy(points_np)\n",
    "type(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:17.376812Z",
     "start_time": "2020-03-09T21:13:17.273090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is data\n",
      " Volume Serial Number is 503D-AB7C\n",
      "\n",
      " Directory of d:\\work\\cercetare\\MLReadingGroup\\2020\\03.March\\10\n",
      "\n",
      "03/09/2020  11:13 PM               387 tensor.pt\n",
      "               1 File(s)            387 bytes\n",
      "               0 Dir(s)  1,222,932,566,016 bytes free\n"
     ]
    }
   ],
   "source": [
    "# tensor serialization\n",
    "torch.save(points, 'tensor.pt')\n",
    "!dir *.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:17.386785Z",
     "start_time": "2020-03-09T21:13:17.378809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del points # now points is undefined\n",
    "points = torch.load('tensor.pt')\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:17.396758Z",
     "start_time": "2020-03-09T21:13:17.388780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recovering the value from a tensor: use item() \n",
    "s = points.sum().item()\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting tensors on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the lines below are usable if GPU version of PyTorch was installed (doh)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, a tensor or a model is to be run on CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:17.405734Z",
     "start_time": "2020-03-09T21:13:17.398753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can change the device as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.159375Z",
     "start_time": "2020-03-09T21:13:17.408727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "points_gpu = points.to(device='cuda')\n",
    "# for multiple GPUs, choose which GPU to be used\n",
    "# points_gpu = points.to(device='cuda:1')\n",
    "print(points_gpu.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.169348Z",
     "start_time": "2020-03-09T21:13:19.162368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar:\n",
    "points_gpu = points.cuda()\n",
    "points_gpu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods with suffix _ modify the objcts in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.189302Z",
     "start_time": "2020-03-09T21:13:19.171343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.207253Z",
     "start_time": "2020-03-09T21:13:19.196277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu.zero_()\n",
    "points_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.223214Z",
     "start_time": "2020-03-09T21:13:19.212234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is executed on GPU\n",
    "points_gpu *= 2\n",
    "points_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.234180Z",
     "start_time": "2020-03-09T21:13:19.227194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Puting the tensor back onto the CPU\n",
    "points_cpu = points_gpu.to(device='cpu')\n",
    "points_cpu.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.246144Z",
     "start_time": "2020-03-09T21:13:19.236171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as\n",
    "points_cpu = points_gpu.cpu()\n",
    "points_cpu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More details can be found in Ref 2, chapter 2. Chapter 3 deals with misc. data input: text, image, time series, tabular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A popular approach in ML is to design a loss function, whose optimization lead to proper estimation of parameters for a predictive model. \n",
    "\n",
    "For a loss function $L = L(w_1, \\dots, w_n, b)$ whose minimum value is sought, the gradient can be used to update the weights $w_i$ and bias $b$ as follows:\n",
    "$$\n",
    "w_i = w_i - \\alpha \\frac{\\partial L}{\\partial w_i}(w_1, \\dots, w_n, b)\n",
    "\\\\\n",
    "b = b - \\alpha \\frac{\\partial L}{\\partial b}(w_1, \\dots, w_n, b)\n",
    "$$\n",
    "with $\\alpha > 0$ as learning rate. PyTorch implements computation of partial derivatives (i.e. of the gradient) automatically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use linear regression as a model to build the relationship between input and output values. The input and output values are, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.256116Z",
     "start_time": "2020-03-09T21:13:19.248138Z"
    }
   },
   "outputs": [],
   "source": [
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T20:24:29.423486Z",
     "start_time": "2020-03-09T20:24:29.282461Z"
    }
   },
   "source": [
    "We convert them into Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.266089Z",
     "start_time": "2020-03-09T21:13:19.261104Z"
    }
   },
   "outputs": [],
   "source": [
    "t_u = torch.tensor(t_u)\n",
    "t_c = torch.tensor(t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model sought has the form:\n",
    "$$\n",
    "t_c = w \\cdot t_u + b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $w$ (weight) and $b$ (bias) are to be determined based on data. We are looking for values of $w$ and $b$ to minimize the loss function\n",
    "$$\n",
    "L(w, b) = \\frac{1}{n} \\sum\\limits_{i=0}^{n-1} (t_u[i]-w_u[i])^2\n",
    "$$\n",
    "where $n$ is the total number of points in the data set. As the loss function is convex in this case, such $w, b$ to minimize $L$ are unique here.\n",
    "\n",
    "Let $m(w, b, x)$ denote the output of the predictive model for trainable parameters $w$, $b$ and current input $x$. For a linear regerssion model, $m$ has the form:\n",
    "$$\n",
    "m(w, b, x) = w\\cdot x + b\n",
    "$$\n",
    "\n",
    "The gradient of the lsoss function is:\n",
    "$$\n",
    "\\nabla_{w, b} L = \\begin{bmatrix}\n",
    "\\frac{\\partial L}{\\partial w}\n",
    "\\\\\n",
    "\\frac{\\partial L}{\\partial b}\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial L}{\\partial m(w, b, x)} \\cdot \\frac{\\partial m(w, b, x)}{\\partial w}\n",
    "\\\\\n",
    "\\frac{\\partial L}{\\partial m(w, b, x)} \\cdot \\frac{\\partial m(w, b, x)}{\\partial b}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For simpel models, partial derivatives as above can be computed manually. However, we *do not reject libraries which compute the gradients by themselves* :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.274075Z",
     "start_time": "2020-03-09T21:13:19.269082Z"
    }
   },
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    return w * t_u + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.283044Z",
     "start_time": "2020-03-09T21:13:19.278058Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow partial derivatives to be computed, the parameters $w$ and $b$ are put into a Tensor, which have the gradient tracking ability set to true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.292021Z",
     "start_time": "2020-03-09T21:13:19.286037Z"
    }
   },
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, as no partial derivatives using $params$ were computed, the tensor's gradient is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.302992Z",
     "start_time": "2020-03-09T21:13:19.297007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.grad is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the gradients - which will be further used to update the corresponfing weights - one must call the `backward` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.317952Z",
     "start_time": "2020-03-09T21:13:19.304986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(model(t_u, *params), t_c)\n",
    "loss.backward()\n",
    "params.grad is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.328924Z",
     "start_time": "2020-03-09T21:13:19.320946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4517.2969,   82.6000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One has to carefully decide which tensors require gradient computation (e..g weights, biases) and which of them do not (e.g. input tensors; they are constant, not updateable).\n",
    "\n",
    "The forward and backward steps are depicted below (source: Ref 2).\n",
    "\n",
    "![Forward and backward propagation](./images/gradients.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that before calling `backward`, one has to manually zero the gradients of the parameters via:\n",
    "\n",
    "```python\n",
    "if params.grad is not None:\n",
    "    params.grad.zero_()\n",
    "```\n",
    "\n",
    "There are only a few models (e.g. recurrent neural networks) for which manual zeroing is not needed.\n",
    "\n",
    "One final note is on input scaling: if the inputs are on a large scale, one cat get NaN on infinity values during model evaluation. To achieve this, it is usggested to scale the values. Popular ranges to be considered are $[0, 1]$, $[-1, 1]$. For input value `t_u` it suffices to multiply the values with 0.1, getting the input vector `t_un`. \n",
    "\n",
    "The full code follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.345876Z",
     "start_time": "2020-03-09T21:13:19.332912Z"
    }
   },
   "outputs": [],
   "source": [
    "t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0])\n",
    "t_u = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4])\n",
    "t_un = 0.1 * t_u\n",
    "\n",
    "def model(t_u, w, b):\n",
    "    return w * t_u + b\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:19.359839Z",
     "start_time": "2020-03-09T21:13:19.347872Z"
    }
   },
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if params.grad is not None:  # <1>\n",
    "            params.grad.zero_()\n",
    "        \n",
    "        t_p = model(t_u, *params) \n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        loss.backward()\n",
    "        \n",
    "        params = (params - learning_rate * params.grad).detach().requires_grad_()\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:21.180293Z",
     "start_time": "2020-03-09T21:13:19.361835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.860116\n",
      "Epoch 1000, Loss 3.828538\n",
      "Epoch 1500, Loss 3.092191\n",
      "Epoch 2000, Loss 2.957697\n",
      "Epoch 2500, Loss 2.933134\n",
      "Epoch 3000, Loss 2.928648\n",
      "Epoch 3500, Loss 2.927830\n",
      "Epoch 4000, Loss 2.927679\n",
      "Epoch 4500, Loss 2.927652\n",
      "Epoch 5000, Loss 2.927647\n"
     ]
    }
   ],
   "source": [
    "best_params = training_loop(\n",
    "    n_epochs = 5000, \n",
    "    learning_rate = 1e-2, \n",
    "    params = torch.tensor([1.0, 0.0], requires_grad=True), # <1> \n",
    "    t_u = t_un, # <2> \n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:21.188303Z",
     "start_time": "2020-03-09T21:13:21.182287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  5.3671, -17.3012], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T21:13:21.205226Z",
     "start_time": "2020-03-09T21:13:21.191263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3593, -1.2992, -1.0648, -1.3448,  1.9155,  0.9439, -2.1068, -1.6009,\n",
       "         2.6755,  2.1160, -1.5903], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_hat = best_params[0] * t_un + best_params[1]\n",
    "t_hat - t_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "1. [Pytorch documentation site](https://pytorch.org/docs/stable/index.html)\n",
    "1. [Free book DEEP LEARNING WITH PYTORCH](https://pytorch.org/deep-learning-with-pytorch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
