{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam \n",
    "Presented during ML reading group, 2019-11-19.\n",
    "\n",
    "Author: Olteanu Mihaela, olteanu.miha@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:01:04.782951Z",
     "start_time": "2019-11-05T18:01:04.728909Z"
    }
   },
   "source": [
    "The [Adam paper](https://arxiv.org/pdf/1412.6980) \n",
    "\n",
    "The Adam method combines the advantages of two other methods: AdaGrad (Duchi et al., 2011) and RMSProp (Tieleman & Hinton, 2012):\n",
    "- it works well with sparse gradients (AdaGrad)\n",
    "- it works well with on-line and non-stationary settings (RMSProp)\n",
    "\n",
    "The Adam method computes the adaptive learning rates from estimates of first and second moments of gradients. The first and second moments of gradients are estimated using exponentially moving averages with hyper-parameters $\\beta_{1}, \\beta_{2} \\in [0, 1)$ decay rates of these moving averages.\n",
    "\n",
    "The advantages of the Adam method are:\n",
    "- the magnitudes of parameter updates are invariant to rescaling of the gradient\n",
    "- its stepsize are approximately bounded by the stepsize hyperparameter\n",
    "- it does not require a stationary objective\n",
    "- it works with sparse gradients\n",
    "- it naturally performs a form of stepsize annealing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T14:45:48.468503Z",
     "start_time": "2019-11-11T14:45:48.460524Z"
    }
   },
   "source": [
    "## The algorithm\n",
    "\n",
    "***\n",
    "\n",
    "**Algorithm 1:** \n",
    "\n",
    "$g_{t}^2$  indicates the elementwise square of $g_{t}$\n",
    "\n",
    "Good default settings for the tested machine learning problems are $\\alpha = 0.001$, $\\beta_{1} = 0.9$, $\\beta_{2} = 0.999$ and $\\epsilon = 10^{-8} $\n",
    "\n",
    "All operations on vectors are element-wise.\n",
    "With $ \\beta_{1}^t$ and $\\beta_{2}^t$ we denote $\\beta_{1}$ and $\\beta_{2}$ to the power $t$\n",
    "\n",
    "***\n",
    "**Require:** $\\alpha$ Stepsize  \n",
    "**Require:** $\\beta_{1}, \\beta_{2} \\in [0, 1)$ : Exponential decay rates for the moment estimates  \n",
    "**Require** $f(\\theta)$ : Stochastic objective function with parameters $\\theta$  \n",
    "**Require** $\\theta_0$ : Initial parameter vector  \n",
    "$\\;\\;\\;\\;$ $m_{0}  \\leftarrow 0$ (Initialize 1st moment vector)  \n",
    "$\\;\\;\\;\\;$ $v_{0}  \\leftarrow 0$ (Initialize 2nd moment vector)  \n",
    "$\\;\\;\\;\\;$ $t  \\leftarrow 0$ (Initialize timestep)  \n",
    "$\\;\\;\\;\\;$ **while** $\\theta_{t}$ not converged **do**:  \n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ $t \\leftarrow t+1$  \n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ $g_{t} \\leftarrow \\nabla(f(\\theta_{t-1}))$ (Get gradients w.r.t. stochastic objective at timestep $t$)  \n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ $m_{t} \\leftarrow \\beta_{1} \\cdot m_{t-1}+(1-\\beta_{1}) \\cdot g_{t}$  (Update biased first moment estimate)  \n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ $v_{t} \\leftarrow \\beta_{2} \\cdot v_{t-1}+(1-\\beta_{2}) \\cdot g_{t}^2$  (Update biased second raw moment estimate)  \n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ $\\hat{m_{t}} \\leftarrow \\dfrac{m_{t}}{(1-\\beta_{1}^t)}$  (Compute bias-corrected first moment estimate)  \n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ $\\hat{v_{t}} \\leftarrow \\dfrac{v_{t}}{(1-\\beta_{2}^t)} $  (Compute bias-corrected second raw moment estimate)  \n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ $\\theta_{t} \\leftarrow \\theta_{t-1} - \\dfrac{\\alpha \\cdot \\hat{m_{t}}}{\\sqrt{\\hat{v_{t}}}+\\varepsilon } $  (Update parameters)  \n",
    "$\\;\\;\\;\\;$**end while**  \n",
    "$\\;\\;\\;\\;$**return** $\\theta_{t}$ (Resulting parameters)  \n",
    "    \n",
    "***\n",
    "* Adam uses estimations of first and second moments of gradient to adapt the learning rate for each weight of the neural network.\n",
    "* The algorithm updates exponential moving averages of the gradient ($m_{t}$) and the squared gradient\n",
    "($v_{t}$) where the hyper-parameters $\\beta_{1}, \\beta_{2} \\in [0, 1)$ control the exponential decay rates of these moving\n",
    "averages. \n",
    "* The moving averages themselves are estimates of the 1st moment (the mean) and the 2nd raw moment (the uncentered variance) of the gradient. \n",
    "* However, these moving averages are initialized as (vectors of) 0â€™s, leading to moment estimates that are biased towards zero, especially during the initial timesteps, and especially when the decay rates are small (i.e. the $\\beta_{s}$ are close to 1). The good news is that this initialization bias can be easily counteracted, resulting in bias-corrected estimates $\\hat{m_{t}}$ and $\\hat{v_{t}}$\n",
    "\n",
    "* The efficiency of the algorithm 1 can be improved with the following rule:\n",
    "\n",
    "    $ \\alpha_{t} = \\alpha \\cdot \\dfrac{\\sqrt(1-\\beta_{2}^t)} {1-\\beta_{1}^t}$ and $\\theta_{t} := \\theta_{t-1} - \\dfrac{\\alpha_{t} \\cdot m_{t}}{\\sqrt{v_{t}}+\\hat{\\varepsilon }} $  \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The update rule\n",
    "\n",
    "* Assuming $\\varepsilon = 0$, the effective step taken in parameter space at timestep $t$ is $\\Delta{t} = \\alpha \\cdot \\dfrac{\\hat{m_{t}}} {\\hat{v_{t}}}$\n",
    "* The effective step size has two bounds:\n",
    "    * In the most severe case of sparsity: when a gradient has been zero at all timesteps except at the current timestep\n",
    "        * $\\mid \\Delta{t} \\mid \\le \\dfrac{\\alpha \\cdot (1-\\beta_{1})}{\\sqrt{1-\\beta_{2}}}$, in the case $(1-\\beta_{1}) \\gt \\sqrt{1-\\beta_{2}}$\n",
    "    * Otherwise\n",
    "        * $\\mid \\Delta{t} \\mid \\le \\alpha$\n",
    " \n",
    "* In more common scenarios, we will have $\\mid \\dfrac{ \\hat{m_{t}} } { \\sqrt{\\hat{v_{t}}} } \\mid  \\; \\approx  1$ since  $\\mid \\dfrac{ E[g_{t}] } { E[g_{t}^2] } \\mid \\le 1$\n",
    "* The effective magnitude of the steps taken in parameter space at each timestep are approximately bounded by the stepsize setting $\\alpha$, i.e., $|\\Delta{t}| \\le \\alpha$\n",
    "\n",
    "\n",
    "* With a slight abuse of terminology, we will call the ratio $\\dfrac{ \\hat{m_{t}} } { \\sqrt{\\hat{v_{t}}} }$ the signal-to-noise ratio (SNR).\n",
    "    * With a smaller SNR the effective stepsize $\\Delta{t}$ will be closer to zero. This is a desirable property, since a smaller SNR means that there is greater uncertainty about whether the direction of $\\hat{m_{t}}$ corresponds to the direction of the true gradient. For example, the SNR value typically becomes closer to 0 towards an optimum, leading to smaller effective steps in parameter space: a form of automatic annealing.\n",
    " \n",
    " \n",
    "* The effective stepsize $\\Delta{t}$ is also invariant to the scale of the gradients; rescaling the gradients $g$ with factor $c$ will scale $\\hat{m_{t}}$ with a factor $c$ and $\\hat{v_{t}}$ with a factor $c^2$, which cancel out: $ \\dfrac{(c \\cdot \\hat{m_{t}})} {\\sqrt{c^2 \\cdot \\hat{v_{t}}}} = \\dfrac{\\hat{m_{t}}}{\\sqrt{\\hat{v_{t}}}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization bias correction\n",
    "\n",
    "Adam uses estimations of first and second moments of gradient to adapt the learning rate for each weight of the neural network. The algorithm updates exponential moving averages of the gradient ($m_{t}$) and the squared gradient\n",
    "($v_{t}$) where the hyper-parameters $\\beta_{1}, \\beta_{2} \\in [0, 1)$ control the exponential decay rates of these moving averages. The moving averages themselves are estimates of the 1st moment (the mean) and the 2nd raw moment (the uncentered variance) of the gradient.\n",
    "Since $m_{t}$ and $v_{t}$ are the estimates of the first moment and the second moment of the gradient, respectively, and the first moment and second moment are the estimates used to adapt the learning rate for each weight of the neural network, we want to ensure that both sets of estimators estimate the same expected value, hence the following equalities must be true:\n",
    "\n",
    "$$E[m_{t}] = E[g{t}]$$\n",
    "$$E[v_{t}] = E[g{t}^2]$$\n",
    "\n",
    "Expected values of the estimators should equal the parameter we're trying to estimate, as it happens. If these properties would held true, it means we have **unbiased estimators**.\n",
    "\n",
    "\n",
    "Looking at some values of $m$:  \n",
    "$m_{0} = 0$  \n",
    "$m_{1} = \\beta_{1} \\cdot m_{0} + (1- \\beta_{1}) \\cdot g_{1} = (1- \\beta_{1}) \\cdot g_{1}$  \n",
    "$m_{2} = \\beta_{1} \\cdot m_{1} + (1- \\beta_{1}) \\cdot g_{2} = \\beta_{1} \\cdot (1- \\beta_{1}) \\cdot g_{1} + (1- \\beta_{1}) \\cdot g_{2} $  \n",
    "$m_{3} = \\beta_{1} \\cdot m_{2} + (1- \\beta_{1}) \\cdot g_{3} = \\beta_{1} ^ 2 \\cdot (1- \\beta_{1}) \\cdot g_{1} + \\beta_{1} \\cdot (1- \\beta_{1}) \\cdot g_{2} + (1- \\beta_{1}) \\cdot g_{3}$  \n",
    "\n",
    "we can rewrite the formula for our moving average:\n",
    "\n",
    "$$ m_{t} = (1-\\beta_{1}) \\cdot \\sum_{i=0}^{t}{\\beta_{1} ^ (t-i) \\cdot g_{i} }$$\n",
    "\n",
    "Now, we can take a look at the expected value of $m_{t}$, to see how it relates to the true first moment, so we can correct for the discrepancy of the two :\n",
    "\n",
    "$$ E[m_{t}] = E[(1-\\beta_{1}) \\cdot \\sum_{i=0}^{t}{\\beta_{1} ^ (t-i) \\cdot g_{i} }]$$  \n",
    "\n",
    "$$ E[m_{t}] = E[g_{t}](1-\\beta_{1}) \\cdot \\sum_{i=0}^{t}{\\beta_{1} ^ (t-i) } + C$$\n",
    "\n",
    "$$ E[m_{t}] = E[g_{t}](1-\\beta_{1}^t)  + C$$\n",
    "\n",
    "Since we have a biased estimator $E[m_{t}]$, we have to correct it, so that the expected value is the one we want. This step is usually referred to as bias correction. The final formulas for our estimator will be as follows:\n",
    "\n",
    "$$ \\hat{m_{t}} = \\dfrac{m_{t}}{1-\\beta_{1}^t}$$\n",
    "$$ \\hat{v_{t}} = \\dfrac{v_{t}}{1-\\beta_{2}^t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T18:34:17.621156Z",
     "start_time": "2019-11-17T18:34:17.618155Z"
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:47.898554Z",
     "start_time": "2019-11-18T19:43:47.893558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.16.5\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "print(f'Numpy version: {np.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:47.952590Z",
     "start_time": "2019-11-18T19:43:47.945204Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import random #to generate sparse data\n",
    "\n",
    "np.random.seed(10) # for reproducibility\n",
    "m_data = 100\n",
    "n_data = 4 #number of features of the data\n",
    "_scales = np.array([1,10, 10,1 ]) # play with these... \n",
    "\n",
    "_parameters = np.array([3, 0.5, 1, 7])\n",
    "\n",
    "def gen_data(m, n, scales, parameters, add_noise=True):\n",
    "    # Adam as Adagrad is designed especially for sparse data.\n",
    "    # produce: X, a 2d tensor with m lines and n columns\n",
    "    # and X[:, k] uniformly distributed in [-scale_k, scale_k] with the first and the last column containing sparse data \n",
    "    #(approx 75% of the elements are 0)\n",
    "    #\n",
    "    # To generate a sparse data matrix with m rows and n columns\n",
    "    # and random values use S = random(m, n, density=0.25).A, where density = density of the data. S will be the \n",
    "    # resulting matrix \n",
    "    # more information at https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.random.html\n",
    "    #\n",
    "    # To obtain X - generate a random matrix with X[:, k] uniformly distributed in [-scale_k, scale_k]\n",
    "    # set X[:, 0] and X[:, -1] to 0 and add matrix S with the sparse data.\n",
    "    #\n",
    "    # let y be X@parameters.T + epsilon, with epsilon ~ N(0, 1); y is a vector with m elements\n",
    "    # parameters - the ideal weights, used to produce output values y\n",
    "    #\n",
    "    X = np.random.rand(m,n) *2*scales - scales\n",
    "    X[:, 0] = 0\n",
    "    X[:, -1] = 0\n",
    "    S = random(m, n, density=0.25).A\n",
    "    X = X + S\n",
    "    y = X@parameters.T + np.random.randn(m)\n",
    "    y = np.reshape(y, (-1, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:47.968554Z",
     "start_time": "2019-11-18T19:43:47.953561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.28428476e-01 -9.58496101e+00  3.03724491e+00  5.66402849e-01]\n",
      " [ 0.00000000e+00 -5.50406709e+00 -6.03874270e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -8.23320372e+00  3.70719637e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  2.43845268e-01  6.25241923e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -4.16247864e+00  8.35548245e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -7.15659905e+00 -2.41271256e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -8.76767173e-01  2.35533957e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  2.81450742e+00  6.92397429e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -3.61527822e+00 -8.19081301e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  6.57362653e+00 -9.06207361e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  6.38573991e+00 -6.02104921e+00  0.00000000e+00]\n",
      " [ 8.70617442e-01  5.09295383e+00 -4.08076586e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -6.69968205e+00 -1.60699768e+00  0.00000000e+00]\n",
      " [ 2.25025940e-01 -5.99602037e+00 -2.31771103e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -8.73909058e-01  6.52245688e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  8.05663521e+00  6.91158976e-01  3.11049320e-01]\n",
      " [ 6.99230218e-01 -2.85636483e+00 -8.29397744e+00  1.20066250e-01]\n",
      " [ 4.35560520e-01  5.47660592e+00 -9.20081583e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  2.72982286e+00 -3.07305700e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  5.26481174e+00  7.56193285e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  4.93441801e-01  1.95673296e+00  4.72786595e-01]\n",
      " [ 0.00000000e+00 -9.49200436e+00 -3.54633767e+00  9.36627065e-01]\n",
      " [ 5.66848670e-01  1.31014040e+00  8.75673187e-03  0.00000000e+00]\n",
      " [ 0.00000000e+00  9.57638292e+00 -3.20584313e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.18452350e+00 -3.63454389e+00  0.00000000e+00]\n",
      " [ 7.66727043e-01  8.03185874e+00 -8.63805453e+00  3.99611848e-01]\n",
      " [ 8.33878745e-01  4.37205621e+00  1.72043960e+00  0.00000000e+00]\n",
      " [ 2.20553036e-01  1.26381369e+00 -3.93728612e+00  5.17770641e-01]\n",
      " [ 6.59370483e-01 -6.81612533e+00 -8.99044660e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -5.71328276e+00  8.14395285e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  5.04992340e+00 -7.76788679e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  2.71701689e+00 -7.04759615e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -9.02743987e+00 -4.80746491e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.50338618e+00  8.44465574e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  6.69417700e-01 -9.70279951e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  5.83513993e+00  1.23114721e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  4.17699653e+00 -7.02933097e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -7.90760511e+00 -1.20789524e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  6.38071728e+00 -8.19786531e+00  4.69963406e-01]\n",
      " [ 0.00000000e+00  2.31111174e+00 -6.03798686e+00  1.11351480e-01]\n",
      " [ 9.75478840e-01 -9.24884648e+00 -9.23008644e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.14590812e+00 -2.29772801e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  2.79623787e+00  5.65429636e+00  0.00000000e+00]\n",
      " [ 2.00911953e-01  5.62121235e+00  2.39389944e+00  3.75041373e-01]\n",
      " [ 0.00000000e+00 -6.47915733e+00 -8.29715875e-01  6.03607471e-01]\n",
      " [ 0.00000000e+00  6.91102632e+00 -6.50372210e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  4.85349155e+00 -8.66049294e-01  7.21664254e-01]\n",
      " [ 0.00000000e+00 -3.22641734e+00 -8.10681919e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -5.88099483e+00  2.45394163e+00  6.81639561e-01]\n",
      " [ 0.00000000e+00  6.30635176e+00 -2.97572994e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  5.69733437e+00 -2.13161775e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -4.54964959e+00  6.58803840e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  2.88653230e+00 -5.73626869e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -3.26135909e+00  7.69127763e+00  4.74423672e-02]\n",
      " [ 0.00000000e+00 -9.01609684e+00 -6.30746324e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  8.38569350e+00 -8.43009761e-01  4.88265796e-01]\n",
      " [ 0.00000000e+00 -1.93060319e+00 -9.51134710e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  4.18211928e+00 -2.88455314e+00  2.54448656e-01]\n",
      " [ 0.00000000e+00  7.62950343e-01  1.18173033e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.42505342e+00  3.62241299e-01  4.42430961e-01]\n",
      " [ 0.00000000e+00 -2.07116242e+00  5.86546466e+00  2.98494435e-01]\n",
      " [ 1.61042178e-01  6.80494632e+00  1.38542799e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -5.42435334e+00  2.29403426e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  2.55123705e+00  6.42432952e+00  0.00000000e+00]\n",
      " [ 2.06067511e-01  2.02103782e+00  9.07080981e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -7.55328158e+00 -8.25515416e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00 -6.13492535e+00 -9.06521546e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  6.55806351e+00  1.01772887e+01  0.00000000e+00]\n",
      " [ 0.00000000e+00 -7.06462371e+00 -7.72079382e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -3.57715937e+00  2.76070163e+00  0.00000000e+00]\n",
      " [ 6.56868150e-01 -3.24490706e+00  7.96048618e+00  2.13258235e-01]\n",
      " [ 0.00000000e+00 -1.18477010e+00  8.73920010e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -6.87231918e+00 -8.26061182e+00  9.25358895e-01]\n",
      " [ 0.00000000e+00  1.68111745e+00  7.56932357e+00  0.00000000e+00]\n",
      " [ 9.70500250e-01  2.90455491e+00 -8.86743594e+00  0.00000000e+00]\n",
      " [ 8.49714595e-02 -6.21941094e+00  6.76473462e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -6.44422503e+00 -8.34759417e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  3.92616544e+00 -5.90476772e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -8.39994438e+00  9.26715011e+00  0.00000000e+00]\n",
      " [ 9.35356900e-01 -8.34725974e+00 -3.09526420e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -5.84145804e+00 -6.39318116e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -4.71605148e+00  2.06635691e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.00970445e+00  2.02880752e+00  5.91105935e-01]\n",
      " [ 0.00000000e+00  4.41599804e+00  1.01612128e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -6.30856527e+00  2.82673574e+00  3.80136209e-02]\n",
      " [ 0.00000000e+00  2.52287338e+00  1.99614283e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  7.09374326e-01 -3.14713749e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  8.91879035e+00  2.89640857e+00  0.00000000e+00]\n",
      " [ 7.50011376e-01  8.06343479e+00 -8.93081739e+00  0.00000000e+00]\n",
      " [ 6.02331842e-01  8.61280010e+00  8.68143801e+00  4.38024101e-01]\n",
      " [ 0.00000000e+00 -7.66241121e+00  6.12763435e+00  0.00000000e+00]\n",
      " [ 7.76805449e-01 -2.85073604e+00  6.33893988e+00  7.71342899e-01]\n",
      " [ 0.00000000e+00  5.09447132e+00 -4.54947648e+00  0.00000000e+00]\n",
      " [ 9.81989522e-01  1.13241385e+00 -1.18525885e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  5.12764716e+00 -9.25355982e+00  0.00000000e+00]\n",
      " [ 9.68976460e-01 -7.11350855e+00  2.28392467e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -3.56868835e+00 -8.64289378e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -6.78294601e+00 -4.64223629e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -6.96627151e+00 -9.08545612e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  6.50929057e+00 -1.15378473e+00  0.00000000e+00]]\n",
      "[[  2.0024736 ]\n",
      " [ -6.6694714 ]\n",
      " [ -2.43545494]\n",
      " [  4.33951713]\n",
      " [  5.95881325]\n",
      " [ -5.68591574]\n",
      " [  2.0358535 ]\n",
      " [  8.26592253]\n",
      " [ -8.58164616]\n",
      " [ -4.90478044]\n",
      " [ -4.25251071]\n",
      " [  3.29224634]\n",
      " [ -2.26898874]\n",
      " [ -3.58260985]\n",
      " [  6.55072984]\n",
      " [  7.82513886]\n",
      " [ -7.24300833]\n",
      " [ -4.16990542]\n",
      " [ -1.78616165]\n",
      " [  7.96925265]\n",
      " [  5.21768494]\n",
      " [ -0.89471119]\n",
      " [  2.54687286]\n",
      " [  0.91195781]\n",
      " [ -3.89737864]\n",
      " [  0.65691508]\n",
      " [  6.45566764]\n",
      " [  1.24756009]\n",
      " [-10.41615208]\n",
      " [  5.14639228]\n",
      " [ -4.30241788]\n",
      " [ -4.13246337]\n",
      " [ -8.47866984]\n",
      " [  7.23655925]\n",
      " [ -7.81483692]\n",
      " [  3.05844197]\n",
      " [ -4.04251292]\n",
      " [ -6.19476221]\n",
      " [ -1.06966314]\n",
      " [ -5.1019856 ]\n",
      " [ -9.65191646]\n",
      " [ -2.10656506]\n",
      " [  7.81272642]\n",
      " [  9.29811209]\n",
      " [  0.89853123]\n",
      " [ -2.50316116]\n",
      " [  7.97039694]\n",
      " [-10.49050576]\n",
      " [  4.16254498]\n",
      " [  0.15999857]\n",
      " [  0.46929628]\n",
      " [  4.31380324]\n",
      " [ -5.97022422]\n",
      " [  6.62998753]\n",
      " [-10.87680885]\n",
      " [  8.00641106]\n",
      " [-10.53002665]\n",
      " [  0.4227351 ]\n",
      " [  0.9277499 ]\n",
      " [  3.46386573]\n",
      " [  7.72178422]\n",
      " [  5.26929615]\n",
      " [ -0.7254132 ]\n",
      " [  6.56171771]\n",
      " [ 11.07089748]\n",
      " [ -3.53630748]\n",
      " [-12.19065404]\n",
      " [ 11.47558689]\n",
      " [-10.17153586]\n",
      " [  0.56926885]\n",
      " [ 10.69790793]\n",
      " [  8.80244795]\n",
      " [ -4.65272321]\n",
      " [  8.43087792]\n",
      " [ -3.58940664]\n",
      " [  4.32021797]\n",
      " [-12.69034642]\n",
      " [ -5.64588293]\n",
      " [  5.16202517]\n",
      " [ -4.3180381 ]\n",
      " [ -8.19561253]\n",
      " [ -1.32998579]\n",
      " [  4.09818321]\n",
      " [  2.2249444 ]\n",
      " [  0.25579068]\n",
      " [  1.32798135]\n",
      " [ -2.4784993 ]\n",
      " [  8.13143279]\n",
      " [ -3.57118809]\n",
      " [ 17.78136899]\n",
      " [  1.91749245]\n",
      " [ 11.38595428]\n",
      " [ -2.87278321]\n",
      " [  1.02600309]\n",
      " [ -6.958641  ]\n",
      " [  0.31297435]\n",
      " [-11.35389443]\n",
      " [ -6.89797032]\n",
      " [-13.38002989]\n",
      " [  2.79790438]]\n"
     ]
    }
   ],
   "source": [
    "X, y = gen_data(m_data, n_data, _scales, _parameters)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define error function, gradient, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:47.999555Z",
     "start_time": "2019-11-18T19:43:47.996554Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_estimate(X, w):\n",
    "    '''Computes the linear regression estimation on the dataset X, using coefficients w\n",
    "    :param X: 2d tensor with m_data lines and n_data columns\n",
    "    :param w: a 1d tensor with n_data coefficients (no intercept)\n",
    "    :return: a 1d tensor with m_data elements y_hat = w @X.T\n",
    "    '''\n",
    "    w = w.reshape(-1, 1)\n",
    "    y_hat = X@w\n",
    "    return y_hat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:48.014649Z",
     "start_time": "2019-11-18T19:43:48.001556Z"
    }
   },
   "outputs": [],
   "source": [
    "def J(X, y, w):\n",
    "    \"\"\"Computes the mean squared error of model. See the picture from last week's sheet.\n",
    "    :param X: input values, of shape m_data x n_data\n",
    "    :param y: ground truth, column vector with m_data values\n",
    "    :param w: column with n_data coefficients for the linear form \n",
    "    :return: a scalar value >= 0\n",
    "    :use the same formula as in the exercise from last week\n",
    "    \"\"\"\n",
    "    w = w.reshape(-1, 1)\n",
    "    expr = (X@w - y)\n",
    "    err = np.asscalar(1.0/(2 * X.shape[0]) * expr.T @ expr)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:48.026553Z",
     "start_time": "2019-11-18T19:43:48.016558Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient(X, y, w):\n",
    "    '''Commputes the gradients to be used for gradient descent. \n",
    "    :param X: 2d tensor with training data\n",
    "    :param y: 1d tensor with y.shape[0] == W.shape[0]\n",
    "    :param w: 1d tensor with current values of the coefficients\n",
    "    :return: gradients to be used for gradient descent. \n",
    "    :use the same formula as in the exercise from last week\n",
    "    '''\n",
    "    n = len(y)\n",
    "    w = w.reshape(-1, 1)\n",
    "    grad = 1.0 / n * X.T @ (X@w - y)\n",
    "    return grad## implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:48.057556Z",
     "start_time": "2019-11-18T19:43:48.051558Z"
    }
   },
   "outputs": [],
   "source": [
    "#The function from last week for comparison\n",
    "def gd_with_momentum(X, y, w_init, eta=1e-1, gamma = 0.9, thresh = 0.001):\n",
    "    \"\"\"Applies gradient descent with momentum coefficient\n",
    "    :params: as in gd_no_momentum\n",
    "    :param gamma: momentum coefficient\n",
    "    :param thresh: the threshold for gradient norm (to stop iterations)\n",
    "    :return: the list of succesive errors and the found w* vector \n",
    "    \"\"\"\n",
    "    w = w_init.reshape(-1, 1)\n",
    "    w_err=[]\n",
    "   \n",
    "    delta = np.zeros_like(w)\n",
    "    while True:\n",
    "        grad = gradient(X, y, w)\n",
    "        err = J(X, y, w)\n",
    "        w_err.append(err)\n",
    "        w_nou = w + gamma * delta - eta * grad\n",
    "        delta = w_nou - w\n",
    "        w = w_nou\n",
    "       \n",
    "        if np.linalg.norm(grad) < thresh :\n",
    "            break;\n",
    "    return w_err, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:50.918557Z",
     "start_time": "2019-11-18T19:43:48.059552Z"
    }
   },
   "outputs": [],
   "source": [
    "w_init = np.array([0, 0, 0, 0])\n",
    "errors_momentum, w_best = gd_with_momentum(X, y, w_init,0.0001, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:50.923555Z",
     "start_time": "2019-11-18T19:43:50.920557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momentum: How many iterations were made: 102146\n"
     ]
    }
   ],
   "source": [
    "print(f'Momentum: How many iterations were made: {len(errors_momentum)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:50.936583Z",
     "start_time": "2019-11-18T19:43:50.925552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.96488751],\n",
       "       [0.48443821],\n",
       "       [0.9629436 ],\n",
       "       [7.32967655]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:51.122551Z",
     "start_time": "2019-11-18T19:43:50.937553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Optimization with momentum')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots()\n",
    "axes.plot(list(range(len(errors_momentum))), errors_momentum)\n",
    "axes.set_xlabel('Epochs')\n",
    "axes.set_ylabel('Error')\n",
    "axes.set_title('Optimization with momentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply AdaGrad and report resulting $\\eta$'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:51.130551Z",
     "start_time": "2019-11-18T19:43:51.123551Z"
    }
   },
   "outputs": [],
   "source": [
    "def ada_grad(X, y, w_init, eta_init=1e-1,  eps = 0.001, thresh = 0.001):\n",
    "    '''Iterates with gradient descent. algorithm\n",
    "    :param X: 2d tensor with data\n",
    "    :param y: 1d tensor, ground truth \n",
    "    :param w_init: 1d tensor with the X.shape[1] initial coefficients\n",
    "    :param eta_init: the initial learning rate hyperparameter\n",
    "    :param eps: the epsilon value from the AdaGrad formula\n",
    "    :param thresh: the threshold for gradient norm (to stop iterations)\n",
    "    :return: the list of succesive errors w_err, the found w - the estimated feature vector \n",
    "    :and rates the learning rates after the final iteration \n",
    "    '''\n",
    "     \n",
    "    w = w_init.reshape(-1, 1)\n",
    "    w_err=[]\n",
    "   \n",
    "    cum_sq_grad = np.zeros(w.shape)\n",
    "    rates = np.zeros(w.shape)+eta_init\n",
    "    while True:\n",
    "        grad = gradient(X, y, w)      \n",
    "        err = J(X, y, w)\n",
    "        w_err.append(err)\n",
    "        w = w - rates * grad\n",
    "        cum_sq_grad += grad**2\n",
    "        rates = eta_init/np.sqrt(eps+cum_sq_grad)\n",
    "        \n",
    "        if np.linalg.norm(grad) < thresh :\n",
    "            break;\n",
    "    return w_err, w, rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:51.421553Z",
     "start_time": "2019-11-18T19:43:51.132554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01515786]\n",
      " [0.00157473]\n",
      " [0.00021369]\n",
      " [0.01046079]]\n"
     ]
    }
   ],
   "source": [
    "w_init = np.array([0,0,0,0])\n",
    "adaGerr, w_ada_best, rates = ada_grad(X, y, w_init)\n",
    "print(rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:51.428552Z",
     "start_time": "2019-11-18T19:43:51.423635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaGrad: How many iterations were made: 9106\n"
     ]
    }
   ],
   "source": [
    "print(f'AdaGrad: How many iterations were made: {len(adaGerr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:51.441591Z",
     "start_time": "2019-11-18T19:43:51.430551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9633901 ],\n",
       "       [0.48443559],\n",
       "       [0.96293089],\n",
       "       [7.32943788]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_ada_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:51.591552Z",
     "start_time": "2019-11-18T19:43:51.443558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Optimization with AdaGrad')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots()\n",
    "axes.plot(list(range(len(adaGerr))),adaGerr)\n",
    "axes.set_xlabel('Epochs')\n",
    "axes.set_ylabel('Error')\n",
    "axes.set_title('Optimization with AdaGrad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Adam and report resulting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:51.600554Z",
     "start_time": "2019-11-18T19:43:51.592557Z"
    }
   },
   "outputs": [],
   "source": [
    "def adam(X, y, w_init, step_size = 0.001, beta_1=0.9, beta_2=0.999,  eps = 1e-8, thresh = 0.001):\n",
    "    '''Iterates with gradient descent. algorithm\n",
    "    :param X: 2d tensor with data\n",
    "    :param y: 1d tensor, ground truth \n",
    "    :param w_init: 1d tensor with the X.shape[1] initial coefficients\n",
    "    :param step_size: the step size hyperparameter\n",
    "    :param beta_1: Exponential decay rate for the 1st moment estimate (mean)\n",
    "    :param beta_1: Exponential decay rate for the 2nd moment estimate (uncentered variance)\n",
    "    :param eps: the epsilon value from the Adam formula (avoid division by zero)\n",
    "    :param thresh: the threshold for gradient norm (to stop iterations)\n",
    "    :return: the list of succesive errors w_err, the found w - the estimated feature vector \n",
    "    :and rates the learning rates after the final iteration \n",
    "    '''\n",
    "    w = w_init.reshape(-1, 1)\n",
    "    w_err=[]\n",
    "    t = 0\n",
    "    m = np.zeros(w.shape)\n",
    "    v = np.zeros(w.shape)\n",
    "    while True:\n",
    "        t += 1\n",
    "        grad = gradient(X, y, w)      \n",
    "        err = J(X, y, w)\n",
    "        w_err.append(err)\n",
    "        #Update biased first moment estimate\n",
    "        #Update biased second raw moment estimate\n",
    "        #Compute bias-corrected first moment estimate)\n",
    "        #Compute bias-corrected second raw moment estimate)\n",
    "        #Update parameters\n",
    "        w = w + delta_w\n",
    "        \n",
    "        if np.linalg.norm(grad) < thresh :\n",
    "            break;\n",
    "    return w_err, w, delta_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:52.138551Z",
     "start_time": "2019-11-18T19:43:51.601557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.04761038e-06]\n",
      " [ 1.25145312e-07]\n",
      " [-7.27710076e-09]\n",
      " [ 4.12973934e-05]]\n"
     ]
    }
   ],
   "source": [
    "w_init = np.array([0,0,0,0])\n",
    "adamErr, w_adam_best, delta_w = adam(X, y, w_init)\n",
    "print(delta_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:52.144551Z",
     "start_time": "2019-11-18T19:43:52.139551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam: How many iterations were made: 11197\n"
     ]
    }
   ],
   "source": [
    "print(f'Adam: How many iterations were made: {len(adamErr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:52.155552Z",
     "start_time": "2019-11-18T19:43:52.145552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.96173056],\n",
       "       [0.4844352 ],\n",
       "       [0.96291422],\n",
       "       [7.32962175]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_adam_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:52.301551Z",
     "start_time": "2019-11-18T19:43:52.156551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Optimization with Adam')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXwcZ53n8c+vu9W6T0uxZTuObHIRSOIEkwlkJrCBkMAsx3AmyxEgbBYGlmNmIDAzu4RZlmsYruHMcF+BcIYbMoYkhCPgkJA7sXM5TnxIsWVZknV092/+qKftsixZsqxWSV3f9+vVr656qrr7V6rkW4+fqq42d0dERNIjk3QBIiIyvxT8IiIpo+AXEUkZBb+ISMoo+EVEUkbBLyKSMgp+SYSZrTKzQTPLzvL1g2a2ZiHVNB+fb2ZuZsdWsIaKvr8sDAp+mREze6WZ3Wpmw2a2zcw+ZWZth/H6B8zs6eV5d9/s7k3uXpxNPeG1983mtZWq6UhN/Hwzu8bMXnOk7xv2nZvZi4+8SqkGCn6Zlpn9PfB+4K1AK3AmcAxwtZnlk6xNZuQiYGd4FgF310OPKR9ACzAIvHhCexOwA3h1mL8M+DbwTWAP8Cfg1LDsK0AJ2Bve621AD+BALqxzDfBu4LdhnR8CS4CvAQPAH4Ge2Oc7cCywPKxffgxH/1k7wGOAXwKPAn3hvdoOo6blwA+IQnMT8D9jn38ZcCXw5bC9twPrpvgbvgv49zBdAwwBHwjz9cAI0B7/fOD/A8WwbBD4eGy7XwtsBHYBnwDsEPvvmLCdLwAKwNIJy98KbAUeAV5d/ruGZX8N3BT+/g8Bl8VeV671VWHZrlDXE4FbgP5yzXosvEfiBeixsB/A+SEwcpMs+xJwRZi+DBgHXhjC7R+A+4GasPwB4Omx104M2WtCuD6G6F8VdwD3AE8PQfhl4Aux1+8LqAk1fS1W07HAuUAt0AVcB3wktu50NV0LfBKoA9YCvcDTYts7AjwLyALvBX4/xd/wHODWMP1k4F7ghtiyPx/ib/KaCe/lwI+ANmBVqOn8Q+y//wP8IUzfCvzdhH27HXg80Ah8nQOD/6nAyUQjA6eEdZ83odZPh7/PM8Lf4/vAUcAKoo7BU5L+b1iPgx8a6pHpdAJ97l6YZNnWsLzsRnf/truPAx8iCoQzD+OzvuDu97r7buCnwL3u/p/hs78FnHaoF5vZpcCJRD1X3H2Tu1/t7qPu3htqespMCjGzo4G/BC519xF3vxn4LPDy2GrXu/tPPBqT/wpw6hRv9zvgODNbApwNfA5YYWZNoZ5rZ1JTzPvcvd/dNwO/IjooTeUVRIFOeI4P97yY6G9+m7sPER3M9nH3a9z9VncvufstwBUc/Pf7f+Hv8wuif8lc4e473P1h4NdMs88kGQp+mU4f0GlmuUmWdYflZQ+VJ9y9BGwhGi6Zqe2x6b2TzDdN9UIzeybwJqIe6d7QdpSZfcPMHjazAeCrHHigOpTlwE533xNre5CoJ1u2LTY9DNRN9ncK9WwgCs2ziYL+t8BZzC74J37upH8XMzsLWA18IzR9HTjZzMoHiuXE9hnR9sVf/xdm9isz6zWz3URDORP/frPeZ5IcBb9M53fAKPD8eKOZNQLPBNbHmo+OLc8AK4nGjiEaFqgIMzuBaNjpxe4eD7L3hs89xd1bgJcBFlt+qJoeATrMrDnWtgp4eJZlXks0rHMa0fmKa4HzgDOIhqAmc6R/s4uItvdmM9sG3BDaXxGetxLbZ0TbF/d1onMcR7t7K9GwjiGLnoJfDikMu7wL+HczO9/Masysh2joZQvREEfZE8zs+aHX+2aiA8bvw7LtwJxedw9gZi3AVcA/u/v1ExY3E50Y7TezFUQnMuOmrCkcQH4LvNfM6szsFOBionMIs3EtUeDe4e5jhPF74P4wDDWZWf/NzKyOaCjnEqKhoPLjfwMvDfvoSuCVZnaSmTUA75zwNs1E/+oZMbMzgP8xm1pk4VHwy7Tc/QPAPwIfJLrC4waiIYKnuftobNWrgJcQXeHxcuD5Ybwfot73P5tZv5n9wxyWdzpwAvCh8OWnQTMbDMveFZbvBn4MfHfCa6er6UKik5iPAN8D3unuV8+yzt8SXcFT7t3fQXQydKrePsBHgRea2S4z+9hhft7ziIZavuzu28oPovMLWaITwj8FPkJ05dOm8Bz3t8C/mNke4P8SHSikCpi7fohFjpyZXUZ0NcjLkq5FRA5NPX4RkZRR8IuIpIyGekREUkY9fhGRlJnsSzkLTmdnp/f09CRdhojIonLjjTf2uXvXxPZFEfw9PT1s2LAh6TJERBYVM3twsnYN9YiIpIyCX0QkZRT8IiIpo+AXEUkZBb+ISMoo+EVEUkbBLyKSMlUd/Ovv3M4nr9mUdBkiIgtKVQf/rzf28elr7k26DBGRBaWqg7+lvoY9owVKJd2ITkSkrLqDvy6HO+wZLSRdiojIglHVwd9aXwPAwN7xadYUEUmPqg7+lhD8uxX8IiL7VHXwq8cvInKwVAS/evwiIvtVdfCXh3oGRhT8IiJlVR386vGLiBysYsFvZkeb2a/M7E4zu93M3hTaO8zsajPbGJ7bK1VDYz5LNmMKfhGRmEr2+AvA37v7Y4Ezgdeb2UnA24H17n4csD7MV4SZ0VKXY2CvruMXESmrWPC7+1Z3/1OY3gPcCawAngt8Kaz2JeB5laoBouEe9fhFRPablzF+M+sBTgNuAJa6+1aIDg7AUVO85hIz22BmG3p7e2f92S31NTq5KyISU/HgN7Mm4DvAm919YKavc/fL3X2du6/r6uqa9eerxy8icqCKBr+Z1RCF/tfc/buhebuZdYfl3cCOStbQUqfgFxGJq+RVPQZ8DrjT3T8UW/QD4KIwfRFwVaVqgDDUo5O7IiL75Cr43mcBLwduNbObQ9s/Au8DrjSzi4HNwIsqWAOt9TUM7B3H3YmORSIi6Vax4Hf364GpkvZplfrciVrqc4wVS4wWStTVZOfrY0VEFqyq/uYu6Nu7IiITVX3wt9Qp+EVE4qo++HVrZhGRA1V98OvHWEREDlT1wd+qWzOLiBwgNcG/e1jBLyICKQj+5rroitXd+hKXiAiQguCvyWZozGc11CMiElR98EN0glcnd0VEIqkI/vJtG0REJCXBrx6/iMh+qQj+tvoa+nVVj4gIkJLgb2/Is2t4LOkyREQWhFQEf1tj1ON396RLERFJXCqCv70hz1ixxPBYMelSREQSl5Lgj769q+EeEZGUBH9bQx5AJ3hFREhJ8LeH4FePX0QkNcFfHupRj19EJBXBv3+oRz1+EZGUBH/o8Q+pxy8ikorgr8lmaK7NaYxfRISUBD+Uv8Sl4BcRSU3wR7dt0FCPiEhqgr+tIa8ev4gIKQr+9oYa9fhFREhV8OsOnSIikKLgb2uoYc9IgUKxlHQpIiKJSk3wl2/b0K9f4hKRlEtN8Je/xKUTvCKSdqkJ/v03alOPX0TSLX3BP6Qev4ikW2qCf/9Qj3r8IpJuqQn+9saox79TY/wiknKpCf7GfJbaXIadGuoRkZRLTfCbGZ1NtfQNjiZdiohIolIT/ABLmvLq8YtI6qUr+BvzPDqo4BeRdKtY8JvZ581sh5ndFmu7zMweNrObw+NZlfr8ySxpquVRDfWISMpVssf/ReD8Sdo/7O5rw+MnFfz8gyxpzNM3NIa7z+fHiogsKBULfne/DthZqfefjSVNecYKJQZHC0mXIiKSmCTG+N9gZreEoaD2qVYys0vMbIOZbejt7Z2TD17SWAugcX4RSbX5Dv5PAY8B1gJbgX+bakV3v9zd17n7uq6urjn58CVN0Ze4Hh3SOL+IpNe8Br+7b3f3oruXgP8AzpjPz+9sUo9fRGReg9/MumOzfwPcNtW6lbC/x6/gF5H0ylXqjc3sCuCpQKeZbQHeCTzVzNYCDjwA/K9Kff5kOsL9enRJp4ikWcWC390vnKT5c5X6vJmozWVprsvRp6EeEUmxVH1zF8K3dzXUIyIplr7g17d3RSTl0hf8jbpRm4ikW/qCv6lWY/wikmqpC/7Opjw7h0YplXS/HhFJp9QF/5LGPCWHXfoJRhFJqdQFf2dz9O3dXp3gFZGUSl3wH9VcB8COAQW/iKRT6oJ/aUvU49+xR8EvIumUuuDf1+PfM5JwJSIiyUhd8NfnszTX5jTUIyKplbrgB+hqqVWPX0RSK5XBf1RzrXr8IpJaqQz+pS11OrkrIqmVyuA/qjka6nHXt3dFJH1SGvx1jIyXGBgpJF2KiMi8S2fwh2v5e3WCV0RSKJ3Br2/vikiKpTP49e1dEUmxdAZ/uFHb9gEN9YhI+qQy+Jtqc9TXZNXjF5FUSmXwmxlHtdQq+EUklVIZ/ABLm+s01CMiqZTe4G+tY9tuBb+IpM+0wW9mWTP71/koZj4tD8Gv394VkbSZNvjdvQg8wcxsHuqZN8vb6hkrlnh0SL+9KyLpkpvhejcBV5nZt4ChcqO7f7ciVc2D7tboS1xbd++lK1zeKSKSBjMN/g7gUeCcWJsDizb4l7fVA/BI/winrEy4GBGReTSj4Hf3V1W6kPkW7/GLiKTJjK7qMbOVZvY9M9thZtvN7Dtmtqj7yR2NeWpzGbbqyh4RSZmZXs75BeAHwHJgBfDD0LZomRndrXU80q8ev4iky0yDv8vdv+DuhfD4ItBVwbrmRXdrvXr8IpI6Mw3+PjN7WbimP2tmLyM62buodbfVsVU9fhFJmZkG/6uBFwPbgK3AC0Pbora8tZ7te0YpFEtJlyIiMm+mvarHzLLAC9z9OfNQz7zqbqujWHJ27Bndd3mniEi1m+k3d587D7XMu+WtUdjrkk4RSZOZDvX8xsw+bmZ/ZWanlx8VrWwexL/EJSKSFjP95u6Tw/O/xNqcA7/Ju+gsb4u+xPWwTvCKSIrMZIw/A3zK3a+ch3rmVXNdDe0NNTy0czjpUkRE5s1MxvhLwBsO943N7PPhm763xdo6zOxqM9sYntsP933n2qqOBjYr+EUkRWY6xn+1mf2DmR0dwrvDzDqmec0XgfMntL0dWO/uxwHrw3yiVnY0qMcvIqky0zH+8jX7r4+1ObBmqhe4+3Vm1jOh+bnAU8P0l4BrgEtnWENFrOpo4Be3b6NYcrKZqvrJARGRSc307pyr5+jzlrr71vCeW83sqKlWNLNLgEsAVq1aNUcff7Cj2xsYLzrbBkZYoWv5RSQFDjnUY2Zvi02/aMKy91SqKAB3v9zd17n7uq6uyt0WaFVHA4CGe0QkNaYb478gNv2OCcsmjt/PxHYz6wYIzztm8R5zqhz8OsErImkxXfDbFNOTzc/ED4CLwvRFwFWzeI851d1WR8bU4xeR9Jgu+H2K6cnmD2BmVwC/A04wsy1mdjHwPuBcM9sInBvmE1WTzbC8rV7BLyKpMd3J3VPNbICod18fpgnzdYd6obtfOMWipx1eiZWna/lFJE0OGfzunp2vQpJ0dHsD6+9K/HSDiMi8mOkXuKraqiUN9A2OMjRaSLoUEZGKU/ADqzsbAbi/byjhSkREKk/BD6zpioL/PgW/iKSAgh/oWdKIGdzXO5h0KSIiFafgB+pqsqxoq+e+XvX4RaT6KfiD1Z2N3NenHr+IVD8Ff/CYribu7x3C/ZDfSxMRWfQU/MGarkaGxopsHxhNuhQRkYpS8AdrOpsAneAVkeqn4A90SaeIpIWCP1jWUkd9TVZX9ohI1VPwB5mM8ZijGtm4Y0/SpYiIVJSCP+aEpS3ctU3BLyLVTcEfc+KyZnr3jLJzaCzpUkREKkbBH3PCsmYA7to2MM2aIiKLl4I/5sQQ/HdruEdEqpiCP6aruZaOxryCX0SqmoI/xsw4YWmzTvCKSFVT8E9wwrJm7tm+h1JJ9+wRkeqk4J/gxGXNDI8VeWiXfnxdRKqTgn+Cx3a3AHDHI7qyR0Sqk4J/ghO7m6nJGrc8vDvpUkREKkLBP0FtLssJy5q5dYuCX0Sqk4J/EievaOOWLf36URYRqUoK/kmcsrKVgZECm3fqBK+IVB8F/yROWdkKwC0a7hGRKqTgn8TxS5vJ5zLcsqU/6VJEROacgn8SNdkMJ3W38Gf1+EWkCin4p7D26DZu3bKb8WIp6VJEROaUgn8KT+zpYO94kdv1RS4RqTIK/ik8sacdgD/evzPhSkRE5paCfwpHtdRxzJIG/viAgl9EqouC/xCe2NPBhgd36YtcIlJVFPyHcEZPBzuHxri3dzDpUkRE5oyC/xDWhXH+P9y/K+FKRETmjoL/EFZ3NrKspY7rN/UmXYqIyJxR8B+CmfFXx3Vy/cY+ivpFLhGpEokEv5k9YGa3mtnNZrYhiRpm6uzjuxgYKfBn3b5BRKpEkj3+/+bua919XYI1TOsvj+3EDH59T1/SpYiIzAkN9UyjvTHPKStauW6jxvlFpDokFfwO/MLMbjSzSxKqYcb+6rgubn6on/7hsaRLERE5YkkF/1nufjrwTOD1Znb2xBXM7BIz22BmG3p7k+1tn3vSUoolZ/2dOxKtQ0RkLiQS/O7+SHjeAXwPOGOSdS5393Xuvq6rq2u+SzzAKStb6W6t42e3b0u0DhGRuTDvwW9mjWbWXJ4GngHcNt91HA4z47zHLeO6e3oZGi0kXY6IyBFJose/FLjezP4M/AH4sbv/LIE6Dst5j1vGaKHEtffoJK+ILG65+f5Ad78POHW+P/dIPbGnnY7GPD++dSvPOrk76XJERGZNl3POUC6b4dmndHP1HdvZvXc86XJERGZNwX8YXvCElYwVSvz4lq1JlyIiMmsK/sNw8opWjl/axLdvfCjpUkREZk3BfxjMjBecvpI/be7XPfpFZNFS8B+m55++kpqs8ZXfPZh0KSIis6LgP0xdzbU8+9TlXLnhIZ3kFZFFScE/C68+azXDY0W+tUFj/SKy+Cj4Z+HxK1o5o6eDL/zmAcYKpaTLERE5LAr+WXr9OcfycP9erlSvX0QWGQX/LJ19XCdPOKadj/9yEyPjxaTLERGZMQX/LJkZf3/u8WwbGNEVPiKyqCj4j8CTj+3kqSd08dH1G9k+MJJ0OSIiM6LgP0KXPftxjBVKvOcndyZdiojIjCj4j1BPZyOvfcoarrr5Ef7zju1JlyMiMi0F/xx4/TnH8tjuFi79zi3s2KMhHxFZ2BT8c6A2l+VjF6xlcLTAW755M4Wiru0XkYVLwT9HjlvazLuf93h+s+lRLvvh7bh70iWJiExq3n+Bq5q9aN3RbOod5DPX3seyljrecM5xSZckInIQBf8cu/S8E9m+e4QP/uIeSg5vfJrCX0QWFgX/HMtkjH978VoyZnzo6nvYPjDCO5/9OPI5jaqJyMKg4K+AbMb41xedytLWOj51zb1s3D7Ih15yKivbG5IuTUREJ3crJZsxLj3/RD56wVpuf2Q35334Or76+wcplnTSV0SSpeCvsOeuXcHP33I2a1e18c/fv41nffTXrL9zu676EZHEKPjnwcr2Br568V/wyZeezmihyMVf2sB5H7mOK/6wmeGxQtLliUjK2GLoea5bt843bNiQdBlzYrxY4qqbH+Hz19/PHVsHqK/Jcu5JS3nOqcs569hO6vPZpEsUkSphZje6+7qD2hX8yXB3Njy4i+/d9DA/uXUr/cPj5HMZzujp4OzjO3nSmk5O7G6mJqt/lInI7Cj4F7DxYonf3fso197Ty6839nLP9kEAanMZTlnZymmr2jl1ZRsndjfTs6SRbMYSrlhEFoOpgl+Xcy4ANdkMZx/fxdnHdwGwbfcIGx7cyU2b+/nT5l188TcPMBbu/1Oby3D80mZOXNbMCcuaOX5pM2u6GlneWk9GBwQRmQH1+BeB0UKRe7YNcte2Ae7etoe7wqNvcHTfOvlchtVLGlnd2cjqruh5TWcjq5Y00NVUi5kOCiJpox7/Ilaby3LyylZOXtl6QHvf4Cibdgxyf98Q9/cNcV/vEBt37GH9XdsZL3rs9RlWttezsr1hwnM03dmU14FBJEUU/ItYZ1MtnU21nLlmyQHthWKJh/v3cl/vEJt3DrNl1zBbdu1ly6693LKln13D4wesX5vL0N1ax9KWOpaF56UtdSxrqWNZay1LW+o4qrlOt50QqRIK/iqUy2Y4ZkkjxyxpnHT54GiBh3ft5eH+6IDw0M5htu4eYcfAKDdt7mfbwAhjhYN/U2BJY56lLXV0NdeGg06eJU15ljTWsqQpT2dT9NzRmKc2p8tSRRYqBX8KNdXmOCGcHJ6Mu9M/PM72PSNs2z3C9oERtu0eZdtANF0eYuodHJ30AAHQXJeLDgSN0cGhvSFPa0MNbfV52hpqaKuvOXC+oYb6mqyGnETmgYJfDmJmtDfmaW/Mc+KylinXc3eGxoo8OjhK3+DYAc+PDo3RNzjKo4Nj3N83xE3D/fQPj++7Omky+WwmHAyiA0FrfZ7W+hqa63I01+Voqs3RXBfNN9XlaKnL0VS7f3ljPqcrm0RmQMEvs2ZmNNVGgTzVsFKcuzMyXqJ/7xj9w+P0D4+zuzy9d8L88Dhbdg1z59YCe0bGGRwtMN397cygKR8dFKKDQU1UX12OhposjbU5GvLZ8MjRWJulPp+jMcw35LM01u6fbsjndF5DqpKCX+aNmVGfz1Kfr6e7tf6wXuvuDI8V2TNSYHB0nIGRQjQ9sv/AMFCeLi8bLdA/PMZDu4bZO1ZkeKzI0GiBwmHcIbUma9QfcNDIUV+TpbYmQ11NNnrkytP722pzseU1Gepy2QnrZKid0JbLmIa6ZF4o+GVRMDMaa3M01uaAuiN6r7FCieGxAsNjRYbHCgyNFvdPjxXZu6+tPB8dMIbHigyNFdg7VmRgpEDvnlFGxouMjJcYKRT3Tc9+G6Mv8+WzGfK5DDVZC8/xtmi6Jldus2j+gLZMrM3IZYxsJhOebf9zdvL27L75zEHrT3yvbMYwg4wZGTOMaNoy5bYwb2BMmNdBLjEKfkmdfC5DPpenrQK/i+PujBZKjE44GETPRUYK+6fj64yOlxgvlhgrOmOFMF1+njA9XnD27h3f11ZeN3ptkfGiM14sHda/bJKw/4ARHRTi8+WDQyYTO5jsO4Dsf/2+98IOeN/97eW2yQ8yB6xrM3uv+Psd8K6H8bmH4z1/czJnrO444veJU/CLzCEz2zfE00pNorUUS9EBoOROoeQUi+G55BRKpfAc5otTtJecYqkUWz6hveS4Rwe8kkPJo/n48/72ctv++VJsHScsL/lB6zjhOdxpIH7DgQOm8YPa44e/qdZl0nV94uJDvO8k687Rcbexdu4vjU4k+M3sfOCjQBb4rLu/L4k6RKpZNBSj71PIweb9kgUzywKfAJ4JnARcaGYnzXcdIiJplcS1amcAm9z9PncfA74BPDeBOkREUimJ4F8BPBSb3xLaDmBml5jZBjPb0NvbO2/FiYhUuySCf7LT3AedBnH3y919nbuv6+rqmoeyRETSIYng3wIcHZtfCTySQB0iIqmURPD/ETjOzFabWR64APhBAnWIiKTSvF/O6e4FM3sD8HOiyzk/7+63z3cdIiJplch1/O7+E+AnSXy2iEjaLYrf3DWzXuDBWb68E+ibw3IWkmrdNm3X4lOt27bYt+sYdz/o6phFEfxHwsw2TPZjw9WgWrdN27X4VOu2Vet26WbjIiIpo+AXEUmZNAT/5UkXUEHVum3arsWnWretKrer6sf4RUTkQGno8YuISIyCX0QkZao6+M3sfDO728w2mdnbk65nOmZ2tJn9yszuNLPbzexNob3DzK42s43huT20m5l9LGzfLWZ2euy9LgrrbzSzi5Lapjgzy5rZTWb2ozC/2sxuCDV+M9zCAzOrDfObwvKe2Hu8I7TfbWbnJbMl+5lZm5l928zuCvvtSVW0v94S/ju8zcyuMLO6xbjPzOzzZrbDzG6Ltc3ZPjKzJ5jZreE1HzNbBD8m7Pt+Eq26HkS3g7gXWAPkgT8DJyVd1zQ1dwOnh+lm4B6iH6v5APD20P524P1h+lnAT4nueHomcENo7wDuC8/tYbp9AWzf3wFfB34U5q8ELgjTnwZeF6b/Fvh0mL4A+GaYPinsx1pgddi/2YS36UvAa8J0Hmirhv1FdKv0+4H62L565WLcZ8DZwOnAbbG2OdtHwB+AJ4XX/BR4ZpL7bkZ/k6QLqODOfhLw89j8O4B3JF3XYW7DVcC5wN1Ad2jrBu4O058BLoytf3dYfiHwmVj7AesltC0rgfXAOcCPwv8kfUBu4v4iuo/Tk8J0LqxnE/dhfL2EtqklhKNNaK+G/VX+3YyOsA9+BJy3WPcZ0DMh+OdkH4Vld8XaD1hvoT6qeahnRj/4slCFfyqfBtwALHX3rQDh+aiw2lTbuBC3/SPA24BSmF8C9Lt7IczHa9xXf1i+O6y/0LZrDdALfCEMYX3WzBqpgv3l7g8DHwQ2A1uJ9sGNLP59VjZX+2hFmJ7YvqBVc/DP6AdfFiIzawK+A7zZ3QcOteokbX6I9kSY2X8Hdrj7jfHmSVb1aZYtqO0i6tmeDnzK3U8DhoiGDaayWLaLMOb9XKLhmeVAI9HvZE+02PbZdA53Oxbb9gHVHfyL8gdfzKyGKPS/5u7fDc3bzaw7LO8GdoT2qbZxoW37WcBzzOwBot9YPofoXwBtZla+Q2y8xn31h+WtwE4W3nZtAba4+w1h/ttEB4LFvr8Ang7c7+697j4OfBd4Mot/n5XN1T7aEqYnti9o1Rz8i+4HX8LVAJ8D7nT3D8UW/QAoX0VwEdHYf7n9FeFKhDOB3eGfrT8HnmFm7aHn9ozQlgh3f4e7r3T3HqL98Et3fynwK+CFYbWJ21Xe3heG9T20XxCuIFkNHEd0Yi0R7r4NeMjMTghNTwPuYJHvr2AzcKaZNYT/Lsvbtqj3Wcyc7KOwbI+ZnRn+Tq+IvdfClfRJhko+iM7Q30N0JcE/JV3PDOr9S6J/Jt4C3BwezyIaK10PbAzPHWF9Az4Rtu9WYF3svV4NbAqPVyW9bbG6nsr+q3rWEIXAJuBbQG1orwvzm8LyNbHX/1PY3rtZAFdPAGuBDWGffZ/oio+q2F/Au4C7gNuArxBdmbPo9hlwBdF5inGiHvrFc7mPgHXhb3Qv8HEmnOxfiA/dskFEJGWqeahHREQmoeAXEUkZBRHEsvMAAAHiSURBVL+ISMoo+EVEUkbBLyKSMgp+STUzK5rZzbHHnN3F1cx64neEFFkoctOvIlLV9rr72qSLEJlP6vGLTMLMHjCz95vZH8Lj2NB+jJmtD/dqX29mq0L7UjP7npn9OTyeHN4qa2b/Ee5r/wszqw/rv9HM7gjv842ENlNSSsEvaVc/YajnJbFlA+5+BtG3MT8S2j4OfNndTwG+BnwstH8MuNbdTyW6X8/tof044BPu/jigH3hBaH87cFp4n9dWauNEJqNv7kqqmdmguzdN0v4AcI673xdunLfN3ZeYWR/RfdzHQ/tWd+80s15gpbuPxt6jB7ja3Y8L85cCNe7+bjP7GTBIdJuH77v7YIU3VWQf9fhFpuZTTE+1zmRGY9NF9p9X+2uie8I8AbgxdsdLkYpT8ItM7SWx59+F6d8S3WEU4KXA9WF6PfA62Pfbwi1TvamZZYCj3f1XRD9O0wYc9K8OkUpRL0PSrt7Mbo7N/8zdy5d01prZDUQdpAtD2xuBz5vZW4l+fetVof1NwOVmdjFRz/51RHeEnEwW+KqZtRLdDfLD7t4/Z1skMg2N8YtMIozxr3P3vqRrEZlrGuoREUkZ9fhFRFJGPX4RkZRR8IuIpIyCX0QkZRT8IiIpo+AXEUmZ/wLI4GbRB2dumwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots()\n",
    "axes.plot(list(range(len(adamErr))),adamErr)\n",
    "axes.set_xlabel('Epochs')\n",
    "axes.set_ylabel('Error')\n",
    "axes.set_title('Optimization with Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adamax algorithm\n",
    "***\n",
    "\n",
    "**Algorithm 2:** AdaMax, a variant of Adam based on the infinity norm. \n",
    "Good default settings for the tested machine learning problems are $\\alpha = 0.002, \\beta_{1} = 0.9$  and  \n",
    "$\\beta_{2} = 0.999$. With $\\beta_{1}^t$ we denote $\\beta_{1}$ to the power $t$. Here, $(\\dfrac{\\alpha} {(1 - \\beta_{1}^t)}\n",
    ")$ is the learning rate with the bias-correction term for the first moment. All operations on vectors are element-wise.\n",
    "\n",
    "***\n",
    "**Require:** $\\alpha$ Stepsize  \n",
    "**Require:** $\\beta_{1}, \\beta_{2} \\in [0, 1)$ : Exponential decay rates for the moment estimates  \n",
    "**Require** $f(\\theta)$ : Stochastic objective function with parameters $\\theta$  \n",
    "**Require** $\\theta_0$ : Initial parameter vector  \n",
    "$\\;\\;\\;\\;$ $m_{0}  \\leftarrow 0$ (Initialize 1st moment vector)  \n",
    "$\\;\\;\\;\\;$ $u_{0}  \\leftarrow 0$ (Initialize the exponentially weighted infinity norm)  \n",
    "$\\;\\;\\;\\;$ $t  \\leftarrow 0$ (Initialize timestep)  \n",
    "$\\;\\;\\;\\;$ **while** $\\theta_{0}$ not converged **do**:  \n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ $t \\leftarrow t+1$  \n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ $g_{t} \\leftarrow \\nabla(f_{t}(\\theta_{t-1}))$ (Get gradients w.r.t. stochastic objective at timestep $t$)  \n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ $m_{t} \\leftarrow \\beta_{1} \\cdot m_{t-1}+(1-\\beta_{1}) \\cdot g_{t}$  (Update biased first moment estimate)  \n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ $u_{t} \\leftarrow max(\\beta_{2} \\cdot u_{t-1}, \\mid g_{t} \\mid )$  (Update the exponentially weighted infinity norm)   \n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ $\\theta_{t} \\leftarrow \\theta_{t-1} - \\dfrac{\\alpha} {(1 - \\beta_{1}^t)} \\cdot \\dfrac{m_{t}}{u_{t}} $  (Update parameters)  \n",
    "$\\;\\;\\;\\;$**end while**  \n",
    "$\\;\\;\\;\\;$**return** $\\theta_{t}$ (Resulting parameters)  \n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Adamax and report resulting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:52.309555Z",
     "start_time": "2019-11-18T19:43:52.302589Z"
    }
   },
   "outputs": [],
   "source": [
    "def adamax(X, y, w_init, step_size = 0.001, beta_1=0.9, beta_2=0.999,  eps = 1e-8, thresh = 0.001):\n",
    "    '''Iterates with gradient descent. algorithm\n",
    "    :param X: 2d tensor with data\n",
    "    :param y: 1d tensor, ground truth \n",
    "    :param w_init: 1d tensor with the X.shape[1] initial coefficients\n",
    "    :param step_size: the step size hyperparameter\n",
    "    :param beta_1: Exponential decay rate for the 1st moment estimate (mean)\n",
    "    :param beta_1: Exponential decay rate for the 2nd moment estimate (uncentered variance)\n",
    "    :param eps: the epsilon value from the Adam formula (avoid division by zero)\n",
    "    :param thresh: the threshold for gradient norm (to stop iterations)\n",
    "    :return: the list of succesive errors w_err, the found w - the estimated feature vector \n",
    "    :and rates the learning rates after the final iteration \n",
    "    '''\n",
    "    w = w_init.reshape(-1, 1)\n",
    "    w_err=[]\n",
    "    t = 0\n",
    "    m = np.zeros_like(w)\n",
    "    u = np.zeros_like(w)\n",
    "    while True:\n",
    "        t += 1\n",
    "        grad = gradient(X, y, w)      \n",
    "        err = J(X, y, w)\n",
    "        w_err.append(err)\n",
    "        #Update biased first moment estimate\n",
    "        #Compute bias-corrected first moment estimate)\n",
    "        #Update biased second raw moment estimate\n",
    "        #Update parameters\n",
    "        w = w + delta_w\n",
    "        \n",
    "        if np.linalg.norm(grad) < thresh :\n",
    "            break;\n",
    "    return w_err, w, delta_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:52.597552Z",
     "start_time": "2019-11-18T19:43:52.310555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.42342929e-05]\n",
      " [ 2.63065640e-07]\n",
      " [-9.95276640e-09]\n",
      " [ 8.67333678e-05]]\n"
     ]
    }
   ],
   "source": [
    "w_init = np.array([0,0,0,0])\n",
    "adamaxErr, w_adamax_best, delta_w = adamax(X, y, w_init)\n",
    "print(delta_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:52.603550Z",
     "start_time": "2019-11-18T19:43:52.598556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaMax: How many iterations were made: 7935\n"
     ]
    }
   ],
   "source": [
    "print(f'AdaMax: How many iterations were made: {len(adamaxErr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:52.614561Z",
     "start_time": "2019-11-18T19:43:52.606552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.96160818],\n",
       "       [0.48443541],\n",
       "       [0.9629132 ],\n",
       "       [7.32970685]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_adamax_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:43:52.778573Z",
     "start_time": "2019-11-18T19:43:52.615556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Optimization with Adamax')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots()\n",
    "axes.plot(list(range(len(adamaxErr))),adamaxErr)\n",
    "axes.set_xlabel('Epochs')\n",
    "axes.set_ylabel('Error')\n",
    "axes.set_title('Optimization with Adamax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography\n",
    "* Diederik P. Kingma, Jimmy Lei Ba, [ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION](https://arxiv.org/pdf/1412.6980)\n",
    "* Sebastian Ruder, [An overview of gradient descent optimization algorithms](https://ruder.io/optimizing-gradient-descent/)\n",
    "* Vitaly Bushaev, [Adam â€” latest trends in deep learning optimization](https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "290.712px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
